You are good at understanding documents with scientific review opinions.
Below is a scientific review for an academic manuscript, please extract fragments that are related to Clarity of the research work.

Definition of Clarity:

The readability of the writing (e.g., structure and language), reproducibility of details, and how accurately what the research question is, what was done and what was the conclusion are presented.


Example input review:

 1) **how can one compare doing LIME over the concatenated (x,z) to having A be diagonal?**\n\nGiven the two interpretable representations $\\bar{x}$ and $\\bar{y}$, LIME uses the concatenated vectors $(\\bar{x}, \\bar{y})$ as features to compute a linear explanation, whereas the proposed feature-based explanation with diagonal $A$ (FbDiag) is computed by taking the squared elementwise differences $(\\bar{x}_i- \\bar{y}_i)^2$ as features (See Section 4.1). They cannot be compared directly since the feature dimensions are not comparable ($(\\bar{x}, \\bar{y})$ has twice the feature dimension).\n\n2) **Optimization over $\\lambda_1$, $\\lambda_2$ is unclear, how can one systematically search over them to get intuitive analogies? Furthermore, why is $\\alpha$ set to 0 in all the experiments? What is the effect of  both quantitatively and qualitatively ?** \n\nFor setting $\\lambda_1$ and $\\lambda_2$, we first note that too high a value of $\\lambda_2$ may result in analogous pairs that do not have similarities close to the input. So we set it to a small value ($0.01$) in all cases and search around that range. Next, when we set $\\lambda_1$ we want to give somewhat equal priority to the first and second terms in equation 2. Hence, we search between $0.1$ and $1.0$. Again, we would like to have good fidelity between the input and the analogous pairs, and this guided our decision. Finally, we also consider how intuitive the analogies are for a randomly chosen set of inputs. At least for STS dataset, this consideration also guided our choice when setting these two hyperparameters. Such a human-in-the-loop process to tune explanations is also seen in prior works (Luss et al. 2021, Madaan et al. 2021, Wu et al. 2021).\n\n$\\alpha$ is set to $0$ because we wanted to evaluate independently the benefit of analogy-based explanations without any influence of feature-based explanations. Qualitatively, higher values of $\\alpha$ (along with high values of $\\lambda_1$) will mean that pairs with close predictions from feature-based explanations will be prioritized.\n\nOur feature-based explanations have high fidelity / low infidelity to the black-box (in-sample) (see Tables 2 and 3 rows named *Infidelity* and *Fidelity* respectively), so high values of $\\alpha$ could mean that the weights for first, second, and third terms in equation 2 are approximately $1+\\lambda_1 \\alpha$, $\\lambda_2$ and $\\lambda_3$, essentially providing higher weight to the black-box fidelity term.\n\n3) **Figure 2: why are the words on the x and y axis shuffled from their original order? Also this kind of visualization is a bit hard to parse, is there a better way to visualize the cross weights (off diagonal elements of A) ?** \n\nWe have provided updated Figures in Section O (Appendix) where we order the words in descending order of their contributions (top left to bottom right). We hope this representation is easier for the reviewer to parse, since you can focus more easily on the top left corner of each figure. We will replace the corresponding figure in the main paper with this one, if the reviewer is satisfied. We dabbled with other visualizations such as showing a list of univariate attributions followed by interaction terms, however, it got unwieldy fast and so we decided on the one we report now.\n\n4) **using google forms and non-paid participants raises questions on the effort:** \n\nThere are many published/established works that have performed unpaid user studies\n(Ramamurthy et al. 2020, Ribeiro et al. 2016, Lundberg et al. 2017, Kim et al. 2017). In fact, since the survey was done by folks willing to do it for free and with backgrounds in data science, engineering and business analytics, as mentioned in the paper (page 7, 3$^\\text{rd}$ paragraph), we expect to have received quality feedback (see Appendix N for the feedback), as opposed to people with unknown backgrounds taking the survey on platforms such as Amazon Turk where the main motive may be to earn the promised payment. An indication of the sincerity is the number of *optional* comments that people taking the survey decided to leave us (Appendix N).\n\n5) **showing participants the same example with different explanation methods:** \n\nThe design you proposed where different examples satisfying a condition are shown to the users is valid. However, our design was also valid since the order in which the explanations from the different methods appeared for different examples was randomized. This will break any systematic bias that could otherwise occur. For example, suppose A, B and C were three explanation methods used to show explanations (in that order) for a specific example. Then for a different example using the same methods, it is equally likely that the order could be any of the six possibilities such as B, C and A, or A, C and B, etc.\n

Example format of extracted fragments in different lines:

I am not sure why is fidelity the \u201cmetric\u201d to compare things across for judging similarity.

They show that their method outperforms the baselines\n\nQuantitative results on 3 datasets: STS, UCI Iris and MEPS where authors show that their method outperforms LIME and other baselines in terms of a metric called \u201cgeneralized infidelity\u201d \n Strengths:\n\n- Novel formalization of objective function for finding analogies and feature attribution for BB similarity learners\n\n- Diverse evaluation of approach using both objective metrics and a user study\n\nWeaknesses/questions:\n\n- On objective 1: how can one compare doing LIME over the concatenated (x,z) to having A be diagonal?\n\n- On objective 2: Optimization over $\\lambda_1, \\lambda_2$ is unclear, how can one systematically search over them to get intuitive analogies?

Also this kind of visualization is a bit hard to parse, is there a better way to visualize the cross weights (off diagonal elements of A) ?\n\n- Issues with user study: 1) using google forms and non-paid participants raises questions on the effort each put into performing the user study.


Target input review:

{{input_document}}

Final extracted fragments (follow the format above in different lines and if no resulted fragments just output "No related fragments"):